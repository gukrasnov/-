import numpy as np
import scipy.special
f_activation = lambda x:scipy.special.expit(x)
def f_derivative(x):
    return x * (1 - x)
input_layer = np.array([[0, 0, 1],
                        [1, 1, 1],
                        [1, 0, 1],
                        [0, 1, 1]])
output_layer = np.array([[0, 1, 1, 0]]).T
synaptic_weight = 2 * np.random.random((3, 1)) - 1
for i in range(10000):
    O_input = np.dot(input_layer, synaptic_weight)
    O_output = f_activation(O_input)
    error = output_layer - O_output
    adjustments = error * f_derivative(O_output)
    synaptic_weight += np.dot(input_layer.T, adjustments)
print('input_layer')
print(input_layer)
print('synaptic_weight')
print(synaptic_weight)
print('O_input')
print(O_input)
print('O_output')
print(O_output)
print('error')
print(error)
print('work')
print(f_activation(np.dot(np.array([[1, 0, 0]]), synaptic_weight)))
print('adjustments')
print(adjustments)
